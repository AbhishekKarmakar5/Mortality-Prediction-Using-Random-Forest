{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (56) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('clean_data6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MODAL_PREMIUM                   0\n",
       "MORTALITY_CLASS                 0\n",
       "PREM_FREQ                       0\n",
       "SUM_ASSURED                     0\n",
       "Base_Data_Curr.PLAN_CODE        0\n",
       "PLAN_NAME                       0\n",
       "COVER_CODE                      0\n",
       "STATUS                          0\n",
       "DOC                             0\n",
       "DOI                             0\n",
       "DOB_OF_LA                       0\n",
       "AGE_OF_LA                       0\n",
       "LPDD                            0\n",
       "NPDD                            0\n",
       "DATE_OF_LAPSE                   0\n",
       "DATE_OF_DEATH                   0\n",
       "POLICY_TERM                     0\n",
       "PREM_PAYING_TERM                0\n",
       "EXTRA_PREMIUM                   0\n",
       "GENDER                          0\n",
       "INSTALLMENT_PREMIUM             0\n",
       "SERVICE_TAX                     0\n",
       "TOTAL_PREMIUM                   0\n",
       "TOTAL_PREMIUM_COLLECTED         0\n",
       "DISTRICT_CODE                1730\n",
       "URBAN_RURAL                     0\n",
       "MEDICAL_NON_MED                 0\n",
       "DISTRIBUTION_CHANNEL            0\n",
       "STATE                           0\n",
       "SA_RISK                         0\n",
       "BONUS_AMT                       0\n",
       "DOI_DEATH                       0\n",
       "HOUSEWIFE_INDICATOR             0\n",
       "surrender_date                  0\n",
       "BONUS_FY                        0\n",
       "BONUS_ACCUM                     0\n",
       "SURR_VAL                        0\n",
       "CHILD_AGE_AT_ENTRY              0\n",
       "MONTHLY_PMT                     0\n",
       "ECS_TAG                         0\n",
       "PREM_STAT                       0\n",
       "DISCON_DATE                     0\n",
       "FUND_AT_DISCON                  0\n",
       "DISCON_CHGS                     0\n",
       "DISCON_CHGS_STAX                0\n",
       "DISCON_EDU_CESS                 0\n",
       "BASE_SA                         0\n",
       "ZONE                            0\n",
       "SUD_REGION                      0\n",
       "SUD_BRANCH_OFFICE               0\n",
       "SMOKING                         0\n",
       "STP_FLAG                        0\n",
       "PIN_CODE                        0\n",
       "EDUCATION                       0\n",
       "ANN_INCOME                      0\n",
       "OCCUPATION                      0\n",
       "DRC_RATE                    49020\n",
       "EXP_COUNT                       0\n",
       "EXP_SA                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X1=dataset[[\"MODAL_PREMIUM\",\"AGE_OF_LA\",\"ANN_INCOME\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SUD_REGION  Region\n",
      "0      Hyderabad    10.0\n",
      "1           Agra     1.0\n",
      "2        Chennai     6.0\n",
      "3         Bhopal     4.0\n",
      "4       Ludhiana    15.0\n",
      "...          ...     ...\n",
      "53118     Bhopal     4.0\n",
      "53119     Ranchi    27.0\n",
      "53120   Ludhiana    15.0\n",
      "53121    Chennai     6.0\n",
      "53122    Chennai     6.0\n",
      "\n",
      "[53123 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "map1={\"M\":1.0,\"F\":0.0}\n",
    "dataset['GEN']=dataset['GENDER'].astype(str).str[0]\n",
    "dataset['GEN']=dataset['GEN'].map(map1)\n",
    "\n",
    "\n",
    "map2={\"U\":1.0,\"R\":0.0}\n",
    "dataset['UR']=dataset['URBAN_RURAL'].astype(str).str[0]\n",
    "dataset['UR']=dataset['UR'].map(map2)\n",
    "\n",
    "\n",
    "\n",
    "data=dataset.STATE.unique()\n",
    "d1 = pd.get_dummies(data)\n",
    "\n",
    "\n",
    "\n",
    "map3={\"MED\":1.0,\"NONM\":0.0}\n",
    "dataset['MN']=dataset['MEDICAL_NON_MED'].astype(str).str[0]\n",
    "dataset['MN']=dataset['MN'].map(map3)\n",
    "\n",
    "\n",
    "map4={\"Y\":1.0,\"N\":0.0}\n",
    "dataset['HW']=dataset['HOUSEWIFE_INDICATOR'].astype(str).str[0]\n",
    "dataset['HW']=dataset['HW'].map(map4)\n",
    "\n",
    "\n",
    "data2=dataset.ZONE.unique()\n",
    "d2 = pd.get_dummies(data2)\n",
    "\n",
    "\n",
    "#data3=dataset.SUD_REGION.unique()\n",
    "#d3 = pd.get_dummies(data3)\n",
    "#print(d3)\n",
    "\n",
    "\n",
    "\n",
    "map5={\"Agra\":1,\"Ahmedabad\":2,\"Bengaluru\":3,\"Bhopal\":4,\"Bhubaneswar\":5,\"Chennai\":6,\"Delhi\":7,\"Ernakulam\":8,\n",
    "      \"Goa Belgaum Hubballi\":9,\"Hyderabad\":10,\"Jaipur\":11,\"Kolkata Metro Suburbs\":12,\"Konkan\":13,\"Lucknow\":14,\n",
    "      \"Ludhiana\":15,\"Meerut\":16,\"Mumbai\":17,\"Nagpur\":18,\"Nashik\":19,\"North Bengal & North East\":20,\n",
    "      \"Patna\":21,\"PSF-EAST\":22,\"PSF-NORTH\":23,\"Pune\":24,\"Pune Suburb\":25,\n",
    "      \"Rajkot\":26,\"Ranchi\":27,\"Rest Of Bengal\":28,\"Satara Sangli Kolhapur\":29,\"Varanasi\":30,\"Vidharbha\":31}\n",
    "dataset['Region']=dataset['SUD_REGION'].astype(str).str[0]\n",
    "dataset['Region']=dataset['Region'].map(map5)\n",
    "\n",
    "\n",
    "for ind in dataset.index:\n",
    "    if(dataset['SUD_REGION'][ind]==\"Agra\"):\n",
    "        dataset['Region'][ind] =  1\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Ahmedabad\"):\n",
    "        dataset['Region'][ind] =  2     \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Bengaluru\"):\n",
    "        dataset['Region'][ind] =  3\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Bhopal\"):\n",
    "        dataset['Region'][ind] =  4        \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Bhubaneswar\"):\n",
    "        dataset['Region'][ind] =  5\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Chennai\"):\n",
    "        dataset['Region'][ind] =  6   \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Delhi\"):\n",
    "        dataset['Region'][ind] =  7    \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Ernakulam\"):\n",
    "        dataset['Region'][ind] =  8\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Goa Belgaum Hubballi\"):\n",
    "        dataset['Region'][ind] =  9        \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Hyderabad\"):\n",
    "        dataset['Region'][ind] =  10\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Jaipur\"):\n",
    "        dataset['Region'][ind] =  11 \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Kolkata Metro Suburbs\"):\n",
    "        dataset['Region'][ind] =  12\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Konkan\"):\n",
    "        dataset['Region'][ind] =  13    \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Lucknow\"):\n",
    "        dataset['Region'][ind] =  14\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Ludhiana\"):\n",
    "        dataset['Region'][ind] =  15       \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Meerut\"):\n",
    "        dataset['Region'][ind] =  16\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Mumbai\"):\n",
    "        dataset['Region'][ind] =  17   \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Nagpur\"):\n",
    "        dataset['Region'][ind] =  18    \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Nashik\"):\n",
    "        dataset['Region'][ind] =  19\n",
    "    elif(dataset['SUD_REGION'][ind]==\"North Bengal & North East\"):\n",
    "        dataset['Region'][ind] =  20        \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Patna\"):\n",
    "        dataset['Region'][ind] =  21\n",
    "    elif(dataset['SUD_REGION'][ind]==\"PSF-EAST\"):\n",
    "        dataset['Region'][ind] =  22\n",
    "    elif(dataset['SUD_REGION'][ind]==\"PSF-NORTH\"):\n",
    "        dataset['Region'][ind] =  23\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Pune\"):\n",
    "        dataset['Region'][ind] =  24     \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Pune Suburb\"):\n",
    "        dataset['Region'][ind] =  25\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Rajkot\"):\n",
    "        dataset['Region'][ind] =  26        \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Ranchi\"):\n",
    "        dataset['Region'][ind] =  27\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Rest Of Bengal\"):\n",
    "        dataset['Region'][ind] =  28   \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Satara Sangli Kolhapur\"):\n",
    "        dataset['Region'][ind] =  29    \n",
    "    elif(dataset['SUD_REGION'][ind]==\"Varanasi\"):\n",
    "        dataset['Region'][ind] =  30\n",
    "    elif(dataset['SUD_REGION'][ind]==\"Vidharbha\"):\n",
    "        dataset['Region'][ind] =  31                 \n",
    "        \n",
    "        \n",
    "print(dataset[[\"SUD_REGION\",\"Region\"]])\n",
    "\n",
    "\n",
    "map6={\"S\":1,\"N\":0}\n",
    "dataset['SMOK']=dataset['SMOKING'].astype(str).str[0]\n",
    "dataset['SMOK']=dataset['SMOK'].map(map6)\n",
    "\n",
    "data4=dataset.EDUCATION.unique()\n",
    "d4 = pd.get_dummies(data4)\n",
    "\n",
    "\n",
    "data5=dataset.OCCUPATION.unique()\n",
    "d5 = pd.get_dummies(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EXP_COUNT\n",
      "0            0.0\n",
      "1            0.0\n",
      "2            0.0\n",
      "3            0.0\n",
      "4            0.0\n",
      "...          ...\n",
      "53118        0.0\n",
      "53119        1.0\n",
      "53120        0.0\n",
      "53121        0.0\n",
      "53122        1.0\n",
      "\n",
      "[53123 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py:4153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "#X=pd.concat([X1,d1,d2,d4,d5,dataset[\"GEN\"],dataset[\"UR\"],dataset[\"MN\"],dataset[\"HW\"],dataset[\"Region\"],dataset[\"SMOK\"]],axis=1)\n",
    "X2=pd.concat([X1,d1,d2,d4,d5,dataset[\"GEN\"],dataset[\"UR\"],dataset[\"MN\"],dataset[\"HW\"],dataset[\"Region\"],dataset[\"SMOK\"]],axis=1)\n",
    "#print(X2[[\"GEN\",\"Region\",\"AGE_OF_LA\"]])\n",
    "\n",
    "X=X2[[\"GEN\",\"Region\",\"AGE_OF_LA\"]]\n",
    "#print(type(X['GEN']))\n",
    "X.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset.loc[dataset.EXP_COUNT==0.01,\"EXP_COUNT\"]=1\n",
    "dataset.loc[dataset.EXP_COUNT==0.02,\"EXP_COUNT\"]=1\n",
    "\n",
    "dataset.loc[dataset.EXP_COUNT==0.03,\"EXP_COUNT\"]=2\n",
    "dataset.loc[dataset.EXP_COUNT==0.04,\"EXP_COUNT\"]=2\n",
    "\n",
    "#print(dataset[\"EXP_COUNT\"].value_counts())\n",
    "\n",
    "Y = dataset[[\"EXP_COUNT\"]]\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    39539\n",
      "1.0    12758\n",
      "2.0      826\n",
      "Name: EXP_COUNT, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(random_state = 42)\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "print(dataset[\"EXP_COUNT\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nY_pred=logreg.predict(X_test)\\nacc_log=round(logreg.score(X_train,Y_train)*100,2)\\n\\nprint(acc_log)\\n\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.metrics import confusion_matrix,classification_report\\nprint(confusion_matrix(Y_test,Y_pred))\\n\\n\\naccuracy_logreg = accuracy_score(Y_test, Y_pred)\\nprint(accuracy_logreg)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Y_pred=logreg.predict(X_test)\n",
    "acc_log=round(logreg.score(X_train,Y_train)*100,2)\n",
    "\n",
    "print(acc_log)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "\n",
    "\n",
    "accuracy_logreg = accuracy_score(Y_test, Y_pred)\n",
    "print(accuracy_logreg)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest classifier\n",
      "83.04 %\n",
      "confusion_matrix for Random Forest\n",
      "[[10607  1277     6]\n",
      " [ 1524  2190    83]\n",
      " [    0   186    64]]\n",
      "Accuracy Score : 0.8069900232164147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88     11890\n",
      "         1.0       0.60      0.58      0.59      3797\n",
      "         2.0       0.42      0.26      0.32       250\n",
      "\n",
      "    accuracy                           0.81     15937\n",
      "   macro avg       0.63      0.57      0.60     15937\n",
      "weighted avg       0.80      0.81      0.80     15937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forestt = RandomForestClassifier(n_estimators=100)\n",
    "random_forestt.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred2 = random_forestt.predict(X_test)\n",
    "\n",
    "random_forestt.score(X_train, Y_train)\n",
    "acc_random_forestt = round(random_forestt.score(X_train, Y_train) * 100, 2)\n",
    "print(\"The accuracy of Random Forest classifier\")\n",
    "print(round(acc_random_forestt,2,), \"%\")\n",
    "print(\"confusion_matrix for Random Forest\")\n",
    "print(confusion_matrix(Y_test, Y_pred2))\n",
    "print(\"Accuracy Score :\",accuracy_score(Y_test, Y_pred2))\n",
    "print(classification_report(Y_test, Y_pred2))\n",
    "with open(\"abhishek.pickle\",'wb') as file:\n",
    "    pickle.dump(random_forestt,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GEN  Region  AGE_OF_LA\n",
      "0  1.0     4.0         35\n",
      "   GEN  Region  AGE_OF_LA\n",
      "0  0.0    10.0         47\n",
      "------------> [0.]\n"
     ]
    }
   ],
   "source": [
    "with open(\"abhishek.pickle\",'rb') as file:\n",
    "    shubham=pickle.load(file)\n",
    "    \n",
    "#print(\"---->\",X.columns)\n",
    "tt=pd.DataFrame({\"GEN\":[1.0],\"Region\":[4.0],\"AGE_OF_LA\":[35]})\n",
    "#print(tt.columns.intersection(X.columns))\n",
    "print(tt)\n",
    "print(X.head(1))\n",
    "\n",
    "output=shubham.predict(tt)\n",
    "print(\"------------>\",output)\n",
    "#accuracy_score(Y_test, output)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16734642655455859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans=KMeans(n_clusters=3)\n",
    "kmeans.fit(X_train,Y_train)\n",
    "Y_pred3=kmeans.predict(X_test)\n",
    "accuracy_kmeans = accuracy_score(Y_test, Y_pred3)\n",
    "print(accuracy_kmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "            \n",
    "callbacks = myCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(3,)), \n",
    "                                  \n",
    "                                    \n",
    "                                    \n",
    "                                    #tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    #tf.keras.layers.Dropout(0.5),\n",
    "                                    \n",
    "                                   \n",
    "                                    \n",
    "                                    #tf.keras.layers.Dense(264, activation=tf.nn.relu),\n",
    "                                    #tf.keras.layers.Dropout(0.25),\n",
    "                                    \n",
    "                                    \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "                                    \n",
    "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN.compile(optimizer = tf.optimizers.Adam(lr=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (37186, 1) was passed for an output of shape (None, 3) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c4b86ce80ed9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_NN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2655\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2656\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2657\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2658\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2659\u001b[0m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shubham mishra\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    510\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    511\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (37186, 1) was passed for an output of shape (None, 3) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "model_NN.fit(X_train, Y_train, epochs=50,batch_size=30,callbacks=[callbacks],validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
